version: "3.8"
services:
  postgres:
    image: postgres:latest
    restart: always
    env_file:
      - backend/.env
    expose:
      - 5432
    ports:
      - "5432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}" ]
      interval: 5s
      timeout: 5s
      retries: 10

  pgadmin:
    image: dpage/pgadmin4
    env_file:
      - backend/.env
    ports:
      - "8002:80"
    depends_on:
      postgres:
        condition: service_healthy

  frontend:
    build:
      context: ./frontend
    image: frontend:latest
    command:
      - yarn build && yarn start
    environment:
      - NODE_ENV=production
    volumes:
      - ./frontend:/src/app
    ports:
      - "3000:3000"
    stdin_open: true
    tty: true

  worker-ray:
    build:
      context: ./backend
    image: backend:latest
    env_file:
      - backend/.env
    command: bash start.sh
    ports:
      - "8000:8000"
      - "8265:8265"
    volumes:
      - ml_models:/mnt/
    healthcheck:
      test: [ "CMD-SHELL", "ray status" ]
      interval: 5s
      timeout: 5s
      retries: 10
    # If you don't have a gpu, comment the deploy section below
    deploy:
      resources:
        reservations:
          devices:
            - count: 1
              capabilities: [ gpu ]
              driver: nvidia

  worker-ray-deployer:
    image: backend:latest
    command: bash -c "sleep 10 && ray job submit -- serve deploy deployment.yaml"
    environment:
      - RAY_ADDRESS=http://worker-ray:8265
    depends_on:
      worker-ray:
        condition: service_healthy

volumes:
  pg_data:
  ml_models:
