services:
  postgres:
    image: postgres:15-alpine
    env_file:
      - backend/secrets.env
    expose:
      - 5432
    ports:
      - 5432:5432
    volumes:
      - pg_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}" ]
      interval: 5s
      timeout: 5s
      retries: 10

  pgadmin:
    image: dpage/pgadmin4
    env_file:
      - backend/secrets.env
    ports:
      - "8002:80"
    depends_on:
      postgres:
        condition: service_healthy

  frontend:
    build:
      context: frontend
      dockerfile: ./Dockerfile
    image: frontend:latest
    entrypoint: ./bin/entrypoint.sh
    volumes:
      - ./frontend:/app
    ports:
      - "3000:3000"
    stdin_open: true
    tty: true

  worker-ray:
    build:
      context: ./backend
    image: backend:latest
    env_file:
      - backend/secrets.env
    command: bash start.sh
    ports:
      - "8000:8000"
      - "8265:8265"
    volumes:
      - ml_models:/mnt/
    healthcheck:
      test: [ "CMD-SHELL", "ray status" ]
      interval: 5s
      timeout: 5s
      retries: 10
    # If you don't have a gpu, comment the deploy section below
    deploy:
      resources:
        reservations:
          devices:
            - count: 1
              capabilities: [ gpu ]
              driver: nvidia

  worker-ray-deployer:
    image: backend:latest
    command: bash -c "sleep 10 && ray job submit -- serve deploy deployment.yaml"
    environment:
      - RAY_ADDRESS=http://worker-ray:8265
    depends_on:
      worker-ray:
        condition: service_healthy

volumes:
  pg_data:
  ml_models:
